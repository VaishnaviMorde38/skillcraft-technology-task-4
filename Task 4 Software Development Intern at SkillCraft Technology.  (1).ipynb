{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63eac0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Software Development Intern at SkillCraft Technology. \n",
    "# Task 4 : Create a program that extracts product information, such as names, prices, and ratings,\n",
    "# from an online e-commerce website and stores the data in a structured format like a CSV file.\n",
    "# Submited by Harinandhan\n",
    "# ID: SCT/JUN24/0751 \n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4b4e59e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraping is a data extraction method used to exclusively gather data from websites. \n",
    "# It is widely used for Data mining or collecting valuable insights from large websites. \n",
    "# Web scraping comes in handy for personal use as well.\n",
    "# Python contains an amazing library called BeautifulSoup to allow web scraping.\n",
    "# We will be using it to scrape product information and save the details in a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8ca27ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract Product Title   Functions Which i have taken\n",
    "def get_title(soup):\n",
    "\n",
    "    try:\n",
    "        # Outer Tag Object\n",
    "        title = soup.find(\"span\", attrs={\"id\":'productTitle'})\n",
    "        \n",
    "        # Inner NavigatableString Object\n",
    "        title_value = title.text\n",
    "\n",
    "        # Title as a string value\n",
    "        title_string = title_value.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        title_string = \"\"\n",
    "\n",
    "    return title_string\n",
    "\n",
    "# Function to extract Product Price\n",
    "def get_price(soup):\n",
    "\n",
    "    try:\n",
    "        price = soup.find(\"span\", attrs={'id':'priceblock_ourprice'}).string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "\n",
    "        try:\n",
    "            # If there is some deal price\n",
    "            price = soup.find(\"span\", attrs={'id':'priceblock_dealprice'}).string.strip()\n",
    "\n",
    "        except:\n",
    "            price = \"\"\n",
    "\n",
    "    return price\n",
    "\n",
    "# Function to extract Product Rating\n",
    "def get_rating(soup):\n",
    "\n",
    "    try:\n",
    "        rating = soup.find(\"i\", attrs={'class':'a-icon a-icon-star a-star-4-5'}).string.strip()\n",
    "    \n",
    "    except AttributeError:\n",
    "        try:\n",
    "            rating = soup.find(\"span\", attrs={'class':'a-icon-alt'}).string.strip()\n",
    "        except:\n",
    "            rating = \"\"\t\n",
    "\n",
    "    return rating\n",
    "\n",
    "# Function to extract Number of User Reviews\n",
    "def get_review_count(soup):\n",
    "    try:\n",
    "        review_count = soup.find(\"span\", attrs={'id':'acrCustomerReviewText'}).string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        review_count = \"\"\t\n",
    "\n",
    "    return review_count\n",
    "\n",
    "# Function to extract Availability Status\n",
    "def get_availability(soup):\n",
    "    try:\n",
    "        available = soup.find(\"div\", attrs={'id':'availability'})\n",
    "        available = available.find(\"span\").string.strip()\n",
    "\n",
    "    except AttributeError:\n",
    "        available = \"Not Available\"\t\n",
    "\n",
    "    return available\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4713b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Define the headers for HTTP requests\n",
    "HEADERS = {\n",
    "    'Accept-Language': 'en-US, en;q=0.5',\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'\n",
    "}\n",
    "\n",
    "def get_title(soup):\n",
    "    title = soup.find(id='productTitle')\n",
    "    return title.get_text(strip=True) if title else 'N/A'\n",
    "\n",
    "def get_price(soup):\n",
    "    price = soup.find('span', {'id': 'priceblock_ourprice'}) or soup.find('span', {'id': 'priceblock_dealprice'})\n",
    "    return price.get_text(strip=True) if price else 'N/A'\n",
    "\n",
    "def get_rating(soup):\n",
    "    rating = soup.find('span', {'class': 'a-icon-alt'})\n",
    "    return rating.get_text(strip=True) if rating else 'N/A'\n",
    "\n",
    "def get_review_count(soup):\n",
    "    reviews = soup.find('span', {'id': 'acrCustomerReviewText'})\n",
    "    return reviews.get_text(strip=True) if reviews else 'N/A'\n",
    "\n",
    "def get_availability(soup):\n",
    "    availability = soup.find('div', {'id': 'availability'})\n",
    "    return availability.get_text(strip=True) if availability else 'N/A'\n",
    "\n",
    "def main():\n",
    "    URL = \"https://www.amazon.com/s?k=playstation+4&ref=nb_sb_noss_2\"\n",
    "\n",
    "    # Make HTTP Request\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "\n",
    "    # Parse the webpage content\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    # Fetch product links\n",
    "    links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})\n",
    "    links_list = [link.get('href') for link in links]\n",
    "\n",
    "    d = {\"title\": [], \"price\": [], \"rating\": [], \"reviews\": [], \"availability\": []}\n",
    "\n",
    "    # Extract product details from each link\n",
    "    for link in links_list:\n",
    "        product_url = \"https://www.amazon.com\" + link\n",
    "        new_webpage = requests.get(product_url, headers=HEADERS)\n",
    "        new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "        d['title'].append(get_title(new_soup))\n",
    "        d['price'].append(get_price(new_soup))\n",
    "        d['rating'].append(get_rating(new_soup))\n",
    "        d['reviews'].append(get_review_count(new_soup))\n",
    "        d['availability'].append(get_availability(new_soup))\n",
    "\n",
    "    # Create DataFrame and save to CSV\n",
    "    amazon_df = pd.DataFrame.from_dict(d)\n",
    "    amazon_df['title'].replace('', np.nan, inplace=True)\n",
    "    amazon_df = amazon_df.dropna(subset=['title'])\n",
    "    amazon_df.to_csv(\"amazon_data.csv\", header=True, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "888674d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hereâ€™s how our out.csv looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "db08fbaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching webpage...\n",
      "Parsing content...\n",
      "Found 0 product links.\n",
      "Creating DataFrame...\n",
      "Saving to CSV...\n",
      "Data saved to amazon_data.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "    URL = \"https://www.amazon.com/s?k=playstation+4&ref=nb_sb_noss_2\"\n",
    "    print(\"Fetching webpage...\")\n",
    "    webpage = requests.get(URL, headers=HEADERS)\n",
    "    print(\"Parsing content...\")\n",
    "    soup = BeautifulSoup(webpage.content, \"html.parser\")\n",
    "\n",
    "    # Fetch product links\n",
    "    links = soup.find_all(\"a\", attrs={'class':'a-link-normal s-no-outline'})\n",
    "    links_list = [link.get('href') for link in links]\n",
    "    print(f\"Found {len(links_list)} product links.\")\n",
    "\n",
    "    d = {\"title\": [], \"price\": [], \"rating\": [], \"reviews\": [], \"availability\": []}\n",
    "\n",
    "    # Extract product details from each link\n",
    "    for link in links_list:\n",
    "        product_url = \"https://www.amazon.com\" + link\n",
    "        print(f\"Fetching product page: {product_url}\")\n",
    "        new_webpage = requests.get(product_url, headers=HEADERS)\n",
    "        new_soup = BeautifulSoup(new_webpage.content, \"html.parser\")\n",
    "\n",
    "        d['title'].append(get_title(new_soup))\n",
    "        d['price'].append(get_price(new_soup))\n",
    "        d['rating'].append(get_rating(new_soup))\n",
    "        d['reviews'].append(get_review_count(new_soup))\n",
    "        d['availability'].append(get_availability(new_soup))\n",
    "\n",
    "    print(\"Creating DataFrame...\")\n",
    "    amazon_df = pd.DataFrame.from_dict(d)\n",
    "    amazon_df['title'].replace('', np.nan, inplace=True)\n",
    "    amazon_df = amazon_df.dropna(subset=['title'])\n",
    "    \n",
    "    print(\"Saving to CSV...\")\n",
    "    amazon_df.to_csv(\"amazon_data.csv\", header=True, index=False)\n",
    "    print(\"Data saved to amazon_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b4413e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can be downloaded as A csv file "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
